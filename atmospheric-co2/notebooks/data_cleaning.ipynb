{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0c2f8a",
   "metadata": {},
   "source": [
    "# 🌫️ Atmospheric CO₂ Data Cleaning & Preparation\n",
    "\n",
    "This notebook processes and enriches the **Mauna Loa daily atmospheric CO₂ dataset** from NOAA and Scripps. The goal is to prepare the data for visualization in Tableau and deeper analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧹 Data Cleaning Objectives\n",
    "\n",
    "- Load the raw daily CO₂ data from the NOAA `.txt` file\n",
    "- Parse and format the date fields correctly\n",
    "- Remove flagged or invalid entries (e.g., `-99.99` values)\n",
    "- Handle missing values using appropriate techniques (e.g., interpolation, rolling averages)\n",
    "- Standardize column names for clarity\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Feature Engineering Plan\n",
    "\n",
    "We’ll create a variety of new features to support time-series analysis and storytelling:\n",
    "\n",
    "| Feature | Description |\n",
    "|--------|-------------|\n",
    "| `date`, `year`, `month`, `day`, `day_of_year` | Temporal breakdown |\n",
    "| `co2_30d_avg`, `co2_365d_avg` | Rolling averages to smooth trends |\n",
    "| `daily_diff`, `monthly_diff`, `pct_change` | Growth and rate-of-change metrics |\n",
    "| `anomaly_flag` | Outlier detection based on z-scores or thresholds |\n",
    "| `sin_day`, `cos_day` | Cyclical encodings for seasonality and radial plots |\n",
    "| `season` | Categorical: Winter, Spring, Summer, Fall |\n",
    "| `forecast` | Modeled prediction of future CO₂ levels |\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 Output Files\n",
    "\n",
    "- `co2_with_features.csv` – Cleaned + engineered features for visualization\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Tools Used\n",
    "\n",
    "- `pandas` – Data manipulation\n",
    "- `numpy` – Numerical operations\n",
    "- `matplotlib / seaborn` – Data exploration\n",
    "- `datetime` – Date parsing and manipulation\n",
    "- `scipy` – Anomaly detection / z-score\n",
    "- `Prophet` - Forecasting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae23646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import requests\n",
    "import os\n",
    "from skmisc.loess import loess\n",
    "from scipy.stats import zscore\n",
    "from prophet import Prophet\n",
    "\n",
    "# 📊 For quick visual checks\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# 🔧 Display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b52cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It was quicker to clean up the data in Excel, so we'll skip through any cleaning and load in the csv into df\n",
    "df = pd.read_csv('../data/co2_daily_cleaned.csv', names = [\"year\", \"month\", \"day\", \"decimal\", \"co2_molfrac\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eec1455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a datetime column\n",
    "\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a1c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create day_of_year column\n",
    "\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70906ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting index to datetime column to calculate 30d/365d rolling averages for co2\n",
    "\n",
    "df.set_index('date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95faf0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rolling 30d/365d rolling averages for co2\n",
    "\n",
    "df['co2_30d_avg'] = df[\"co2_molfrac\"].rolling(window='30D').mean().round(2)\n",
    "df['co2_365_avg'] = df[\"co2_molfrac\"].rolling(window='365D').mean().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad8ef35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add daily differences\n",
    "\n",
    "df['daily_diff'] = df['co2_molfrac'].diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd4432c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add monthly differences\n",
    "monthly = df.resample('M').mean(numeric_only=True)\n",
    "monthly['monthly_diff'] = monthly['co2_molfrac'].diff().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0465b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily, and monthly, percentage change\n",
    "\n",
    "df['pct_change'] = df['co2_molfrac'].pct_change() * 100\n",
    "monthly['monthly_change'] = monthly['co2_molfrac'].pct_change() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c7b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polar coordinates so we can create seasonal/radial plots\n",
    "\n",
    "df['sin_day'] = np.sin((2*np.pi*df['day_of_year'])/365) # y value\n",
    "df['cos_day'] = np.cos((2*np.pi*df['day_of_year'])/365) # x value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddd0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize dates by season\n",
    "# We'll use meteorlogical seasons since they are a little bit easier to work with\n",
    "\n",
    "def set_season(month):\n",
    "    \n",
    "    if (month == 12 or month == 1 or month == 2):\n",
    "        return \"Winter\"\n",
    "    elif (month == 3 or month == 4 or month == 5):\n",
    "        return \"Spring\"\n",
    "    elif (month == 6 or month == 7 or month == 8):\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Autumn\"\n",
    "\n",
    "df['season'] = df.index.to_series().dt.month.apply(set_season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b86fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loess smoothing on Day of year and Co2 molfrac\n",
    "\n",
    "df['co2_loess'] = None\n",
    "\n",
    "# Loop through each year and apply LOESS\n",
    "for year, group in df.groupby('year'):\n",
    "    x = group['day_of_year'].values\n",
    "    y = group['co2_molfrac'].values\n",
    "\n",
    "    model = loess(x, y, span=0.2, degree=1)\n",
    "    model.fit()\n",
    "    smoothed = model.predict(x).values\n",
    "\n",
    "    df.loc[group.index, 'co2_loess'] = smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d43131c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrend the data\n",
    "yearly_avg = df.groupby('year')['co2_molfrac'].transform('mean')\n",
    "df['detrended'] = df['co2_molfrac'] - yearly_avg\n",
    "\n",
    "# Compute seasonal component\n",
    "seasonal_component = df.groupby('day_of_year')['detrended'].transform('mean')\n",
    "df['seasonal_component'] = seasonal_component\n",
    "\n",
    "# Compute deseasoned values and attach annual average to each row\n",
    "df['deseasoned'] = df['co2_molfrac'] - df['seasonal_component']\n",
    "\n",
    "# z-score calculation setup for anomaly detection\n",
    "\n",
    "# calculate within-year means\n",
    "df['deseasoned_365_avg'] = df.groupby('year')['deseasoned'].transform('mean')\n",
    "\n",
    "# calculate within-year standard deviation\n",
    "df['deseasoned_365_std'] = df.groupby('year')['deseasoned'].transform('std')\n",
    "\n",
    "# calculate 1000 day rolling mean\n",
    "window = 3650\n",
    "df['rolling_mean'] = df['deseasoned'].rolling(window=3650, min_periods=1000).mean()\n",
    "\n",
    "#calculate 1000 day rolling std\n",
    "df['rolling_std'] = df['deseasoned'].rolling(window=3650, min_periods=1000).std()\n",
    "\n",
    "# calculate z-score\n",
    "df['z-score'] = (df['deseasoned'] - df['deseasoned_365_avg'])/df['deseasoned_365_std']\n",
    "\n",
    "# calculate z-score for 1000 rolling day window\n",
    "\n",
    "df['z-score_1000'] = (df['deseasoned'] - df['rolling_mean'])/df['rolling_std']\n",
    "\n",
    "# flag any anomalies, where z-score > 2\n",
    "df['anomaly_flag'] = (df['z-score']).abs() > 2\n",
    "\n",
    "# flag any anomalies for 10000 rolling day window\n",
    "\n",
    "df['anomaly_flag_1000'] = (df['z-score_1000']).abs() > 2\n",
    "\n",
    "# Create new df to store anomaly data\n",
    "df_anomaly = pd.DataFrame()\n",
    "df_anomaly['date'] = df.reset_index().date\n",
    "df_anomaly = df_anomaly.set_index('date')\n",
    "df_anomaly[['year', 'month', 'day', 'day_of_year', 'co2_molfrac', 'season', 'detrended', \n",
    "            'seasonal_component', 'deseasoned', 'deseasoned_365_avg', \n",
    "            'deseasoned_365_std', 'z-score', 'anomaly_flag', 'rolling_mean',\n",
    "           'rolling_std', 'z-score_1000', 'anomaly_flag_1000']] = df[['year', 'month', 'day', 'day_of_year', 'co2_molfrac', 'season', 'detrended', \n",
    "            'seasonal_component', 'deseasoned', 'deseasoned_365_avg', \n",
    "            'deseasoned_365_std', 'z-score', 'anomaly_flag', 'rolling_mean',\n",
    "           'rolling_std', 'z-score_1000', 'anomaly_flag_1000']]\n",
    "\n",
    "# Remove anomaly-related columns from main df\n",
    "df = df.drop(columns=['detrended', 'deseasoned', 'seasonal_component', 'deseasoned_365_avg', \n",
    "                      'deseasoned_365_std', 'z-score', 'anomaly_flag', 'rolling_mean',\n",
    "                      'rolling_std', 'z-score_1000', 'anomaly_flag_1000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e87b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anomaly tooltip dataframe\n",
    "\n",
    "df_anomaly_tooltips = pd.DataFrame()\n",
    "df_anomaly_tooltips = df_anomaly[df_anomaly['z-score_1000'].abs() > 2]\n",
    "df_anomaly_tooltips = df_anomaly_tooltips[['deseasoned', 'rolling_mean', 'z-score_1000']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2b4792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create explanation column for anomalies\n",
    "    \n",
    "def generate_explanation_and_event(row):\n",
    "    z = row['z-score_1000']\n",
    "    year = row.name.year\n",
    "    month = row.name.month\n",
    "\n",
    "    if z > 2:\n",
    "        if year == 1998 and month in [3, 4, 5]:\n",
    "            return \"Elevated CO₂ likely due to 1997–98 El Niño and widespread biomass burning.\", True\n",
    "        elif year == 1983 and month in [1, 2, 3]:\n",
    "            return \"CO₂ spike likely influenced by 1982–83 El Niño and El Chichón volcanic effects.\", True\n",
    "        elif year == 2016 and month in [3, 4, 5]:\n",
    "            return \"2015–16 El Niño led to warmer conditions and reduced biospheric CO₂ uptake.\", True\n",
    "        elif year == 2020 and month in [4, 5, 6]:\n",
    "            return \"Atmospheric changes during COVID-19 may have affected CO₂ transport and uptake.\", True\n",
    "        elif year == 2005 and month in [7, 8]:\n",
    "            return \"Amazon drought in 2005 likely reduced rainforest carbon absorption.\", True\n",
    "        elif year == 2010 and month in [7, 8, 9]:\n",
    "            return \"Russian wildfires and heatwave likely contributed to elevated CO₂.\", True\n",
    "        elif year == 2003 and month in [6, 7, 8]:\n",
    "            return \"European heatwave in 2003 may have decreased photosynthetic CO₂ uptake.\", True\n",
    "        else:\n",
    "            return \"Higher-than-expected CO₂; possibly due to warm conditions, drought, or biospheric stress.\", False\n",
    "\n",
    "    return \"\", False  # For z <= 2\n",
    "\n",
    "\n",
    "df_anomaly_tooltips[['explanation', 'event']] = df_anomaly_tooltips.apply(generate_explanation_and_event, axis=1, result_type='expand')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb89a850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:42:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:42:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# co2 forecasting\n",
    "\n",
    "df_prophet = pd.DataFrame({\n",
    "    'ds': df.index,\n",
    "    'y': df['co2_molfrac'].values\n",
    "})\n",
    "\n",
    "model = Prophet(yearly_seasonality=True)\n",
    "model.fit(df_prophet)\n",
    "\n",
    "# Create future dates (e.g., next 10 years = 120 months)\n",
    "future = model.make_future_dataframe(periods=5475, freq='D')\n",
    "\n",
    "# Predict future values\n",
    "forecast = model.predict(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb412bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out dates so we have past 20 years and future 15 years of data\n",
    "last_date = df_prophet['ds'].max() - pd.DateOffset(years=25)\n",
    "forecast_future = forecast[forecast['ds'] > last_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f569474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to date\n",
    "forecast_future = forecast_future.set_index('ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2aecdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average yearly co2, percentage change, then loess smoothed curve -- all in a new dataframe\n",
    "\n",
    "# Step 1: Calculate yearly CO₂ average\n",
    "yearly_df = df.groupby('year')['co2_molfrac'].mean().reset_index()\n",
    "yearly_df.rename(columns={'co2_molfrac': 'yearly_co2_avg'}, inplace=True)\n",
    "\n",
    "# Step 2: Calculate percentage change year over year\n",
    "yearly_df['pct_change'] = yearly_df['yearly_co2_avg'].pct_change() * 100\n",
    "\n",
    "# Step 3: Set 'year' as the index\n",
    "yearly_df.set_index('year', inplace=True)\n",
    "\n",
    "# Step 4: Apply LOESS smoothing to percentage change\n",
    "loess_model = loess(\n",
    "    yearly_df.index.values,\n",
    "    yearly_df['pct_change'].values,\n",
    "    span=0.2,\n",
    "    degree=1\n",
    ")\n",
    "loess_model.fit()\n",
    "smoothed = loess_model.predict(yearly_df.index.values).values\n",
    "\n",
    "# Optional: Add smoothed values to the DataFrame\n",
    "yearly_df['smoothed_pct_change'] = smoothed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23f9e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframes we created\n",
    "monthly.to_csv('../data/monthly_features.csv', index=True)\n",
    "df.to_csv('../data/features.csv', index=True)\n",
    "forecast_future.to_csv('../data/forecast_future.csv', index=True)\n",
    "yearly_df.to_csv('../data/yearly_co2_average.csv', index=True)\n",
    "df_anomaly.to_csv('../data/anomaly.csv', index=True)\n",
    "df_anomaly_tooltips.to_csv('../data/anomaly_tooltips.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1949d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
